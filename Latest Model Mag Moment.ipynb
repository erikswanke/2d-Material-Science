{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "All necessary imports\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import scipy.spatial.distance as distance\n",
    "import scipy\n",
    "\n",
    "from pandas import read_csv\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from minepy import MINE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from mrmr import mrmr_classif\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('magneticmoment_Ef_data.csv', header=0)\n",
    "mine = MINE(alpha=0.6, c=15) #a=.6 recommended by paper, c of more than 15 has no change in result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = []\n",
    "for j in range(len(df.columns)):\n",
    "    if( not (isinstance(df.iloc[0][j], np.float64) or isinstance(df.iloc[0][j], np.int64)) ):\n",
    "        tmp.append(df.columns[j])\n",
    "\n",
    "#print(tmp)\n",
    "df = df.drop(columns=tmp)\n",
    "df = df.drop(columns=['formation_energy'])\n",
    "#df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['energy', 'covalentrad_max_dif', 'nvalence_std_dif', 'nvalence_sum_dif', 'dipole_avg', 'nvalence_max_dif', 'num_d', 'cmpd_sigma_d', 'Nup_mean', 'nvalence_std', 'nvalence_avg', 'cmpd_skew_d']\n"
     ]
    }
   ],
   "source": [
    "y_axis = \"magnetic_moment\"\n",
    "MIC_corrs = []\n",
    "\n",
    "for j in range(len(df.columns)):\n",
    "    \n",
    "    mine.compute_score(df.iloc[:,j],df[y_axis]) \n",
    "    tmp_corr = mine.mic() \n",
    "\n",
    "    colname = df.columns[j]\n",
    "\n",
    "    MIC_corrs.append((colname, tmp_corr))\n",
    "\n",
    "corrdf = pd.DataFrame.from_records(MIC_corrs[1:], columns=['feature', 'correlation'])\n",
    "corrdf = corrdf.dropna()\n",
    "corrdf = corrdf.sort_values(by=['correlation'])\n",
    "\n",
    "mic_corrdf = corrdf.iloc[-13:-1]\n",
    "\n",
    "\n",
    "\n",
    "mic_descriptors = list(mic_corrdf[\"feature\"])\n",
    "print(mic_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove what we want to predict\n",
    "labels = np.array(df['magnetic_moment'])\n",
    "\n",
    "df = df.drop(columns=['magnetic_moment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrmr_candidates = corrdf.iloc[-60:-1]\n",
    "mrmr_input = list(mrmr_candidates[\"feature\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [00:00<00:00, 39.56it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#make dataframes for mic top 12, paper top 12, total df\n",
    "mic_descriptors = mic_descriptors\n",
    "df_input = df[mrmr_input]\n",
    "mrmr_descriptors = mrmr_classif(df_input, labels, K = 12)\n",
    "paper_descriptors = [\"Nup_mean\", \"cs_bob\",  \"nvalence_max_dif\", \"dipole_avg\", \n",
    "                     \"Nup_var\", \"nvalence_std\", \"nvalence_avg\", \"dipole_std_dif\",  \n",
    "                     \"vdwradius_avg\", \"covalentrad_std_dif\", \"dipole_max_dif\", \"hardness_mean\" ]\n",
    "\n",
    "df_all = df\n",
    "df_mic = df[mic_descriptors]\n",
    "df_mrmr = df[mrmr_descriptors]\n",
    "df_paper = df[paper_descriptors]\n",
    "\n",
    "#----------------------------------------------------------------------\n",
    "#get list of feature names for all, MIC top 12, paper top 12\n",
    "#----------------------------------------------------------------------\n",
    "feature_list_all = list(df_all.columns)\n",
    "\n",
    "feature_list_mic = list(df_mic.columns)\n",
    "\n",
    "feature_list_mrmr = list(df_mrmr.columns)\n",
    "\n",
    "feature_list_paper = list(df_paper.columns)\n",
    "\n",
    "#get numpy array of all, mic, and paper features\n",
    "features_all   = np.array(df_all)\n",
    "features_mic   = np.array(df_mic)\n",
    "features_mrmr  = np.array(df_mrmr)\n",
    "features_paper = np.array(df_paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "\n",
    "def make_train_test_split(features, labels):\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25,\n",
    "                                                                           random_state = 42)\n",
    "    return train_features, test_features, train_labels, test_labels \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_r_sq(predictions, test_labels):\n",
    "    r_sq = metrics.r2_score(predictions, test_labels)\n",
    "    return r_sq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_importances(rf, feature_list):\n",
    "    # Get numerical feature importances\n",
    "    importances = list(rf.feature_importances_)\n",
    "\n",
    "    # List of tuples with variable and importance\n",
    "    feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "\n",
    "    # Sort the feature importances by most important first\n",
    "    feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "    # Print out the feature and importances \n",
    "    print(\"Most important variables:\")\n",
    "    [print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances[:40]];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_graph(test_labels, predictions, r_sq, mode):\n",
    "    x = test_labels\n",
    "    y=predictions\n",
    "    slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(predictions, test_labels)\n",
    "\n",
    "    y2=(test_labels * slope + intercept)\n",
    "    plt.scatter(x,y, color='c', label=\"data\")\n",
    "    plt.plot(x,y2, color='b', label=\"fitted line\")\n",
    "\n",
    "    plt.xlabel(\"True magnetic moment\")\n",
    "    plt.ylabel(\"Predicted\")\n",
    "\n",
    "\n",
    "    lab = \"r^2=%.3f \" % (r_sq)\n",
    "\n",
    "    plt.plot([], [], ' ', label=lab )\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title(\"Magnetic Moment predictions using {} descriptors\".format(mode))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_and_graph(labels, features, feature_list, mode, print_features=False):\n",
    "    train_features, test_features, train_labels, test_labels = make_train_test_split(features, labels)\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators= 1000, random_state=429)\n",
    "    # Train the model on training data\n",
    "    rf.fit(train_features, train_labels);\n",
    "    predictions = rf.predict(test_features)\n",
    "    r_sq = get_r_sq(predictions, test_labels)\n",
    "    print(\"r squared value for\", mode + \": \", round(r_sq, 2))\n",
    "    if(print_features):\n",
    "        print_importances(rf, feature_list)\n",
    "    make_graph(test_labels,predictions, r_sq, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#run_and_graph(labels, features_all, feature_list_all, \"All\", print_features=False)\n",
    "run_and_graph(labels, features_mic, feature_list_mic, \"MIC\", print_features=True)\n",
    "run_and_graph(labels, features_mrmr, feature_list_mrmr, \"mRMR\", print_features=False)\n",
    "#run_and_graph(labels, features_paper, feature_list_paper, \"Paper\", print_features=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [2, 3, 4, 5, 6, 7, 8],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "\"\"\" hyperparameter tuning for random forest\"\"\"\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = list(range(2,9))\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth}\n",
    "\n",
    "#pprint.pprint(random_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter tuning for MIC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
